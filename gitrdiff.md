# Git Diff Report

**Generated**: Sun, Dec 21, 2025 10:19:23 PM

**Local Branch**: move

**Comparing Against**: origin/move

---

## Uncommitted Changes (working directory)

### Modified/Staged Files

```
?? gitrdiff.md
```

### New Untracked Files

#### `gitrdiff.md`

```
```

---

## Commits Ahead (local changes not on remote)

```
c6474a2 feat: Add experiment database for agent memory
a494fe6 feat: Add ModelRegistry wiring and backend simulation test
2fa7675 feat: Add agent training tool (/agent/train-from-scan)
8ab1343 feat: Add backend infrastructure from PR #9 (registries, simulation session, account manager)
```

## Commits Behind (remote changes not pulled)

```
```

---

## File Changes (what you'd get from remote)

```
 gitrdiff.md                             |  50 ++++++
 src/components/SimulationView.tsx       |   2 +-
 src/core/manifest.py                    | 235 -------------------------
 src/core/registries.py                  | 272 -----------------------------
 src/features/indicator_registry_init.py | 167 ------------------
 src/models/model_registry_init.py       | 153 -----------------
 src/policy/scanner_registry_init.py     | 103 -----------
 src/server/main.py                      | 203 +---------------------
 src/sim/account_manager.py              | 149 ----------------
 src/sim/simulation_session.py           | 296 --------------------------------
 src/storage/__init__.py                 |   9 -
 src/storage/experiments_db.py           | 287 -------------------------------
 tests/test_backend_simulation.py        | 288 -------------------------------
 13 files changed, 52 insertions(+), 2162 deletions(-)
```

---

## Full Diff (green = new on remote, red = removed on remote)

```diff
diff --git a/gitrdiff.md b/gitrdiff.md
new file mode 100644
index 0000000..c1d0c48
--- /dev/null
+++ b/gitrdiff.md
@@ -0,0 +1,50 @@
+# Git Diff Report
+
+**Generated**: Sun, Dec 21, 2025  8:18:35 PM
+
+**Local Branch**: strategy
+
+**Comparing Against**: origin/strategy
+
+---
+
+## Uncommitted Changes (working directory)
+
+### Modified/Staged Files
+
+```
+?? gitrdiff.md
+```
+
+### New Untracked Files
+
+#### `gitrdiff.md`
+
+```
+```
+
+---
+
+## Commits Ahead (local changes not on remote)
+
+```
+```
+
+## Commits Behind (remote changes not pulled)
+
+```
+```
+
+---
+
+## File Changes (what you'd get from remote)
+
+```
+```
+
+---
+
+## Full Diff (green = new on remote, red = removed on remote)
+
+```diff
+```
diff --git a/src/components/SimulationView.tsx b/src/components/SimulationView.tsx
index d83eafc..63d0760 100644
--- a/src/components/SimulationView.tsx
+++ b/src/components/SimulationView.tsx
@@ -475,7 +475,7 @@ export const SimulationView: React.FC<SimulationViewProps> = ({
                         <label className="text-xs text-slate-400">CNN Threshold</label>
                         <input
                             type="number"
-                            step="0.01"
+                            step="0.05"
                             min="0.1"
                             max="0.9"
                             value={threshold}
diff --git a/src/core/manifest.py b/src/core/manifest.py
deleted file mode 100644
index 075b3f7..0000000
--- a/src/core/manifest.py
+++ /dev/null
@@ -1,235 +0,0 @@
-"""
-Run Manifest
-Unified contract for all run outputs (SCAN/REPLAY/TRAIN).
-"""
-
-from dataclasses import dataclass, field
-from typing import Dict, Any, List, Optional
-from datetime import datetime
-from pathlib import Path
-import json
-
-from src.core.enums import RunMode
-
-
-@dataclass
-class ScannerConfig:
-    """Configuration for a scanner used in the run."""
-    scanner_id: str
-    params: Dict[str, Any] = field(default_factory=dict)
-    
-    def to_dict(self) -> Dict[str, Any]:
-        return {
-            'scanner_id': self.scanner_id,
-            'params': self.params,
-        }
-
-
-@dataclass
-class ModelConfig:
-    """Configuration for a model used in the run."""
-    model_id: str
-    model_path: Optional[str] = None
-    role: str = "REPLAY_ONLY"
-    params: Dict[str, Any] = field(default_factory=dict)
-    
-    def to_dict(self) -> Dict[str, Any]:
-        return {
-            'model_id': self.model_id,
-            'model_path': self.model_path,
-            'role': self.role,
-            'params': self.params,
-        }
-
-
-@dataclass
-class ArtifactRefs:
-    """References to artifacts produced by the run."""
-    decisions: Optional[str] = None  # Path to decisions.jsonl
-    trades: Optional[str] = None     # Path to trades.jsonl
-    series: Optional[str] = None     # Path to full_series.json
-    indicators: Optional[str] = None # Path to indicators.jsonl
-    metrics: Optional[str] = None    # Path to metrics.json
-    events: Optional[str] = None     # Path to events.jsonl (for replay)
-    
-    def to_dict(self) -> Dict[str, Any]:
-        return {
-            'decisions': self.decisions,
-            'trades': self.trades,
-            'series': self.series,
-            'indicators': self.indicators,
-            'metrics': self.metrics,
-            'events': self.events,
-        }
-
-
-@dataclass
-class Provenance:
-    """Provenance tracking for reproducibility."""
-    git_hash: Optional[str] = None
-    config_hash: Optional[str] = None
-    created_by: str = "mlang2"
-    
-    def to_dict(self) -> Dict[str, Any]:
-        return {
-            'git_hash': self.git_hash,
-            'config_hash': self.config_hash,
-            'created_by': self.created_by,
-        }
-
-
-@dataclass
-class RunManifest:
-    """
-    Unified run manifest.
-    
-    This is the single source of truth for what a run contains.
-    All outputs (SCAN/REPLAY/TRAIN) produce this manifest.
-    
-    The UI reads this to know:
-    - What mode the run was in
-    - What scanners/models were used
-    - What artifacts are available
-    - How to reproduce the run
-    """
-    # Identity
-    run_id: str
-    created_at: str  # ISO timestamp
-    run_mode: RunMode
-    
-    # Market context
-    symbol: str = "MES"
-    timeframe: str = "1m"
-    start_date: Optional[str] = None
-    end_date: Optional[str] = None
-    
-    # Components used
-    scanners: List[ScannerConfig] = field(default_factory=list)
-    models: List[ModelConfig] = field(default_factory=list)
-    indicators: List[str] = field(default_factory=list)  # List of indicator IDs used
-    
-    # Artifacts produced
-    artifacts: ArtifactRefs = field(default_factory=ArtifactRefs)
-    
-    # Provenance
-    provenance: Provenance = field(default_factory=Provenance)
-    
-    # Summary stats (optional)
-    stats: Dict[str, Any] = field(default_factory=dict)
-    
-    def to_dict(self) -> Dict[str, Any]:
-        return {
-            'run_id': self.run_id,
-            'created_at': self.created_at,
-            'run_mode': self.run_mode.value,
-            'symbol': self.symbol,
-            'timeframe': self.timeframe,
-            'start_date': self.start_date,
-            'end_date': self.end_date,
-            'scanners': [s.to_dict() for s in self.scanners],
-            'models': [m.to_dict() for m in self.models],
-            'indicators': self.indicators,
-            'artifacts': self.artifacts.to_dict(),
-            'provenance': self.provenance.to_dict(),
-            'stats': self.stats,
-        }
-    
-    def save(self, path: Path):
-        """Save manifest to JSON file."""
-        with open(path, 'w') as f:
-            json.dump(self.to_dict(), f, indent=2)
-    
-    @classmethod
-    def load(cls, path: Path) -> 'RunManifest':
-        """Load manifest from JSON file."""
-        with open(path) as f:
-            data = json.load(f)
-        
-        # Reconstruct nested objects
-        scanners = [ScannerConfig(**s) for s in data.get('scanners', [])]
-        models = [ModelConfig(**m) for m in data.get('models', [])]
-        artifacts = ArtifactRefs(**data.get('artifacts', {}))
-        provenance = Provenance(**data.get('provenance', {}))
-        
-        return cls(
-            run_id=data['run_id'],
-            created_at=data['created_at'],
-            run_mode=RunMode(data['run_mode']),
-            symbol=data.get('symbol', 'MES'),
-            timeframe=data.get('timeframe', '1m'),
-            start_date=data.get('start_date'),
-            end_date=data.get('end_date'),
-            scanners=scanners,
-            models=models,
-            indicators=data.get('indicators', []),
-            artifacts=artifacts,
-            provenance=provenance,
-            stats=data.get('stats', {}),
-        )
-    
-    @classmethod
-    def create_for_scan(
-        cls,
-        run_id: str,
-        scanner_id: str,
-        scanner_params: Dict[str, Any],
-        start_date: str,
-        end_date: str,
-    ) -> 'RunManifest':
-        """Factory method for SCAN mode runs."""
-        return cls(
-            run_id=run_id,
-            created_at=datetime.utcnow().isoformat() + 'Z',
-            run_mode=RunMode.SCAN,
-            start_date=start_date,
-            end_date=end_date,
-            scanners=[ScannerConfig(scanner_id=scanner_id, params=scanner_params)],
-            artifacts=ArtifactRefs(
-                decisions=f"{run_id}/decisions.jsonl",
-            ),
-        )
-    
-    @classmethod
-    def create_for_replay(
-        cls,
-        run_id: str,
-        model_id: str,
-        model_path: str,
-        start_date: str,
-        end_date: str,
-    ) -> 'RunManifest':
-        """Factory method for REPLAY mode runs."""
-        return cls(
-            run_id=run_id,
-            created_at=datetime.utcnow().isoformat() + 'Z',
-            run_mode=RunMode.REPLAY,
-            start_date=start_date,
-            end_date=end_date,
-            models=[ModelConfig(model_id=model_id, model_path=model_path, role="REPLAY_ONLY")],
-            artifacts=ArtifactRefs(
-                decisions=f"{run_id}/decisions.jsonl",
-                trades=f"{run_id}/trades.jsonl",
-                events=f"{run_id}/events.jsonl",
-            ),
-        )
-    
-    @classmethod
-    def create_for_train(
-        cls,
-        run_id: str,
-        start_date: str,
-        end_date: str,
-    ) -> 'RunManifest':
-        """Factory method for TRAIN mode runs."""
-        return cls(
-            run_id=run_id,
-            created_at=datetime.utcnow().isoformat() + 'Z',
-            run_mode=RunMode.TRAIN,
-            start_date=start_date,
-            end_date=end_date,
-            artifacts=ArtifactRefs(
-                decisions=f"{run_id}/decisions.jsonl",
-                trades=f"{run_id}/trades.jsonl",
-                metrics=f"{run_id}/metrics.json",
-            ),
-        )
diff --git a/src/core/registries.py b/src/core/registries.py
deleted file mode 100644
index 764bd75..0000000
--- a/src/core/registries.py
+++ /dev/null
@@ -1,272 +0,0 @@
-"""
-Plugin Registries
-Central registration for scanners, models, and indicators.
-"""
-
-from typing import Dict, Callable, Any, List, Protocol
-from dataclasses import dataclass
-
-
-# =============================================================================
-# Scanner Registry
-# =============================================================================
-
-class Scanner(Protocol):
-    """Protocol for scanner implementations."""
-    def scan(self, step_result: Any) -> bool:
-        """Return True if conditions are met."""
-        ...
-
-
-@dataclass
-class ScannerInfo:
-    """Metadata about a registered scanner."""
-    scanner_id: str
-    name: str
-    description: str
-    params_schema: Dict[str, Any]  # JSON schema for params
-
-
-class ScannerRegistry:
-    """
-    Registry for scanner implementations.
-    
-    Usage:
-        @ScannerRegistry.register("ema_cross", "EMA Cross", "Trigger on EMA crossover")
-        class EMACrossScanner:
-            def __init__(self, fast=12, slow=26):
-                self.fast = fast
-                self.slow = slow
-            
-            def scan(self, step_result):
-                # Implementation
-                pass
-    """
-    
-    _registry: Dict[str, Callable] = {}
-    _info: Dict[str, ScannerInfo] = {}
-    
-    @classmethod
-    def register(
-        cls,
-        scanner_id: str,
-        name: str,
-        description: str = "",
-        params_schema: Dict[str, Any] = None
-    ):
-        """Decorator to register a scanner."""
-        def decorator(scanner_class):
-            cls._registry[scanner_id] = scanner_class
-            cls._info[scanner_id] = ScannerInfo(
-                scanner_id=scanner_id,
-                name=name,
-                description=description,
-                params_schema=params_schema or {},
-            )
-            return scanner_class
-        return decorator
-    
-    @classmethod
-    def create(cls, scanner_id: str, **params) -> Scanner:
-        """Create scanner instance by ID."""
-        if scanner_id not in cls._registry:
-            raise ValueError(f"Unknown scanner: {scanner_id}")
-        return cls._registry[scanner_id](**params)
-    
-    @classmethod
-    def list_all(cls) -> List[ScannerInfo]:
-        """List all registered scanners."""
-        return list(cls._info.values())
-    
-    @classmethod
-    def get_info(cls, scanner_id: str) -> ScannerInfo:
-        """Get info for a specific scanner."""
-        if scanner_id not in cls._info:
-            raise ValueError(f"Unknown scanner: {scanner_id}")
-        return cls._info[scanner_id]
-
-
-# =============================================================================
-# Model Registry
-# =============================================================================
-
-class PolicyModel(Protocol):
-    """Protocol for policy model implementations."""
-    def predict(self, features: Any) -> Dict[str, Any]:
-        """Return model prediction."""
-        ...
-
-
-@dataclass
-class ModelInfo:
-    """Metadata about a registered model."""
-    model_id: str
-    name: str
-    description: str
-    input_schema: Dict[str, Any]
-    output_schema: Dict[str, Any]
-
-
-class ModelRegistry:
-    """
-    Registry for model implementations.
-    
-    Usage:
-        @ModelRegistry.register("fusion_cnn", "Fusion CNN Model")
-        class FusionModelWrapper:
-            def __init__(self, model_path):
-                self.model = load_model(model_path)
-            
-            def predict(self, features):
-                return self.model.forward(**features)
-    """
-    
-    _registry: Dict[str, Callable] = {}
-    _info: Dict[str, ModelInfo] = {}
-    
-    @classmethod
-    def register(
-        cls,
-        model_id: str,
-        name: str,
-        description: str = "",
-        input_schema: Dict[str, Any] = None,
-        output_schema: Dict[str, Any] = None
-    ):
-        """Decorator to register a model."""
-        def decorator(model_class):
-            cls._registry[model_id] = model_class
-            cls._info[model_id] = ModelInfo(
-                model_id=model_id,
-                name=name,
-                description=description,
-                input_schema=input_schema or {},
-                output_schema=output_schema or {},
-            )
-            return model_class
-        return decorator
-    
-    @classmethod
-    def create(cls, model_id: str, **params) -> PolicyModel:
-        """Create model instance by ID."""
-        if model_id not in cls._registry:
-            raise ValueError(f"Unknown model: {model_id}")
-        return cls._registry[model_id](**params)
-    
-    @classmethod
-    def list_all(cls) -> List[ModelInfo]:
-        """List all registered models."""
-        return list(cls._info.values())
-    
-    @classmethod
-    def get_info(cls, model_id: str) -> ModelInfo:
-        """Get info for a specific model."""
-        if model_id not in cls._info:
-            raise ValueError(f"Unknown model: {model_id}")
-        return cls._info[model_id]
-
-
-# =============================================================================
-# Indicator Registry
-# =============================================================================
-
-@dataclass
-class IndicatorSeries:
-    """
-    First-class indicator series for visualization.
-    Not hardcoded in chart - generic overlay rendering.
-    """
-    indicator_id: str
-    name: str
-    type: str  # 'line', 'histogram', 'band', 'marker'
-    points: List[Dict[str, Any]]  # [{time, value}, ...] or specific format per type
-    style: Dict[str, Any] = None  # Color, line width, etc.
-    
-    def to_dict(self) -> Dict[str, Any]:
-        return {
-            'indicator_id': self.indicator_id,
-            'name': self.name,
-            'type': self.type,
-            'points': self.points,
-            'style': self.style or {},
-        }
-
-
-@dataclass
-class IndicatorInfo:
-    """Metadata about a registered indicator."""
-    indicator_id: str
-    name: str
-    description: str
-    output_type: str  # 'line', 'histogram', 'band', 'marker'
-    params_schema: Dict[str, Any]
-
-
-class IndicatorRegistry:
-    """
-    Registry for indicator implementations.
-    
-    Usage:
-        @IndicatorRegistry.register("ema", "EMA", output_type="line")
-        class EMAIndicator:
-            def __init__(self, period=20):
-                self.period = period
-            
-            def compute(self, stepper) -> IndicatorSeries:
-                # Calculate EMA
-                return IndicatorSeries(...)
-    """
-    
-    _registry: Dict[str, Callable] = {}
-    _info: Dict[str, IndicatorInfo] = {}
-    
-    @classmethod
-    def register(
-        cls,
-        indicator_id: str,
-        name: str,
-        output_type: str = "line",
-        description: str = "",
-        params_schema: Dict[str, Any] = None
-    ):
-        """Decorator to register an indicator."""
-        def decorator(indicator_class):
-            cls._registry[indicator_id] = indicator_class
-            cls._info[indicator_id] = IndicatorInfo(
-                indicator_id=indicator_id,
-                name=name,
-                description=description,
-                output_type=output_type,
-                params_schema=params_schema or {},
-            )
-            return indicator_class
-        return decorator
-    
-    @classmethod
-    def create(cls, indicator_id: str, **params):
-        """Create indicator instance by ID."""
-        if indicator_id not in cls._registry:
-            raise ValueError(f"Unknown indicator: {indicator_id}")
-        return cls._registry[indicator_id](**params)
-    
-    @classmethod
-    def list_all(cls) -> List[IndicatorInfo]:
-        """List all registered indicators."""
-        return list(cls._info.values())
-    
-    @classmethod
-    def get_info(cls, indicator_id: str) -> IndicatorInfo:
-        """Get info for a specific indicator."""
-        if indicator_id not in cls._info:
-            raise ValueError(f"Unknown indicator: {indicator_id}")
-        return cls._info[indicator_id]
-    
-    @classmethod
-    def compute_all(cls, stepper: Any, indicator_ids: List[str]) -> List[IndicatorSeries]:
-        """Compute multiple indicators at once."""
-        results = []
-        for indicator_id in indicator_ids:
-            indicator = cls.create(indicator_id)
-            series = indicator.compute(stepper)
-            results.append(series)
-        return results
diff --git a/src/features/indicator_registry_init.py b/src/features/indicator_registry_init.py
deleted file mode 100644
index 6dd8451..0000000
--- a/src/features/indicator_registry_init.py
+++ /dev/null
@@ -1,167 +0,0 @@
-"""
-Indicator Registration  
-Wire existing indicators into the IndicatorRegistry.
-"""
-
-from src.core.registries import IndicatorRegistry, IndicatorSeries
-import pandas as pd
-from typing import Any
-
-
-# =============================================================================
-# Register built-in indicators
-# =============================================================================
-
-@IndicatorRegistry.register(
-    indicator_id="ema",
-    name="Exponential Moving Average",
-    output_type="line",
-    description="EMA of closing prices",
-    params_schema={
-        "period": {"type": "integer", "default": 20, "min": 2}
-    }
-)
-class EMAIndicator:
-    """EMA indicator."""
-    def __init__(self, period: int = 20):
-        self.period = period
-    
-    def compute(self, stepper: Any) -> IndicatorSeries:
-        """Compute EMA from stepper data."""
-        # Extract price data
-        df = stepper.df if hasattr(stepper, 'df') else pd.DataFrame()
-        
-        if len(df) == 0:
-            return IndicatorSeries(
-                indicator_id=f"ema_{self.period}",
-                name=f"EMA {self.period}",
-                type="line",
-                points=[]
-            )
-        
-        # Calculate EMA
-        ema = df['close'].ewm(span=self.period, adjust=False).mean()
-        
-        # Convert to points
-        points = [
-            {
-                'time': row['time'].isoformat() if hasattr(row['time'], 'isoformat') else str(row['time']),
-                'value': float(val) if pd.notna(val) else None
-            }
-            for (idx, row), val in zip(df.iterrows(), ema)
-        ]
-        
-        return IndicatorSeries(
-            indicator_id=f"ema_{self.period}",
-            name=f"EMA {self.period}",
-            type="line",
-            points=points,
-            style={'color': '#00ff00', 'lineWidth': 2}
-        )
-
-
-@IndicatorRegistry.register(
-    indicator_id="atr",
-    name="Average True Range",
-    output_type="line",
-    description="ATR volatility indicator",
-    params_schema={
-        "period": {"type": "integer", "default": 14, "min": 2}
-    }
-)
-class ATRIndicator:
-    """ATR indicator."""
-    def __init__(self, period: int = 14):
-        self.period = period
-    
-    def compute(self, stepper: Any) -> IndicatorSeries:
-        """Compute ATR from stepper data."""
-        df = stepper.df if hasattr(stepper, 'df') else pd.DataFrame()
-        
-        if len(df) == 0:
-            return IndicatorSeries(
-                indicator_id=f"atr_{self.period}",
-                name=f"ATR {self.period}",
-                type="line",
-                points=[]
-            )
-        
-        # Calculate True Range
-        high_low = df['high'] - df['low']
-        high_close = (df['high'] - df['close'].shift()).abs()
-        low_close = (df['low'] - df['close'].shift()).abs()
-        
-        tr = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)
-        atr = tr.ewm(span=self.period, adjust=False).mean()
-        
-        # Convert to points
-        points = [
-            {
-                'time': row['time'].isoformat() if hasattr(row['time'], 'isoformat') else str(row['time']),
-                'value': float(val) if pd.notna(val) else None
-            }
-            for (idx, row), val in zip(df.iterrows(), atr)
-        ]
-        
-        return IndicatorSeries(
-            indicator_id=f"atr_{self.period}",
-            name=f"ATR {self.period}",
-            type="line",
-            points=points,
-            style={'color': '#ff9900', 'lineWidth': 1}
-        )
-
-
-@IndicatorRegistry.register(
-    indicator_id="vwap",
-    name="Volume Weighted Average Price",
-    output_type="line",
-    description="VWAP - resets daily",
-    params_schema={}
-)
-class VWAPIndicator:
-    """VWAP indicator."""
-    def __init__(self):
-        pass
-    
-    def compute(self, stepper: Any) -> IndicatorSeries:
-        """Compute VWAP from stepper data."""
-        df = stepper.df if hasattr(stepper, 'df') else pd.DataFrame()
-        
-        if len(df) == 0:
-            return IndicatorSeries(
-                indicator_id="vwap",
-                name="VWAP",
-                type="line",
-                points=[]
-            )
-        
-        # Simple VWAP (not session-aware for now)
-        typical_price = (df['high'] + df['low'] + df['close']) / 3
-        vwap = (typical_price * df['volume']).cumsum() / df['volume'].cumsum()
-        
-        # Convert to points
-        points = [
-            {
-                'time': row['time'].isoformat() if hasattr(row['time'], 'isoformat') else str(row['time']),
-                'value': float(val) if pd.notna(val) else None
-            }
-            for (idx, row), val in zip(df.iterrows(), vwap)
-        ]
-        
-        return IndicatorSeries(
-            indicator_id="vwap",
-            name="VWAP",
-            type="line",
-            points=points,
-            style={'color': '#ffff00', 'lineWidth': 2}
-        )
-
-
-# Auto-register on import
-def register_all_indicators():
-    """
-    Register all available indicators.
-    Call this at startup to populate the registry.
-    """
-    pass
diff --git a/src/models/model_registry_init.py b/src/models/model_registry_init.py
deleted file mode 100644
index cc9af09..0000000
--- a/src/models/model_registry_init.py
+++ /dev/null
@@ -1,153 +0,0 @@
-"""
-Model Registration
-Wire existing models into the ModelRegistry.
-"""
-
-from src.core.registries import ModelRegistry
-
-
-# =============================================================================
-# Register built-in models
-# =============================================================================
-
-@ModelRegistry.register(
-    model_id="fusion_cnn",
-    name="Fusion CNN Model",
-    description="Multi-timeframe CNN with MLP context fusion",
-    input_schema={
-        "x_price_1m": {"type": "array", "shape": [None, 5]},
-        "x_price_5m": {"type": "array", "shape": [None, 5]},
-        "x_price_15m": {"type": "array", "shape": [None, 5]},
-        "x_context": {"type": "array", "shape": [None]},
-    },
-    output_schema={
-        "logits": {"type": "array", "shape": [3]},
-        "probs": {"type": "array", "shape": [3]},
-    }
-)
-class FusionCNNWrapper:
-    """Wrapper for FusionModel."""
-    def __init__(self, model_path: str):
-        from src.models.fusion import FusionModel
-        from src.core.enums import ModelRole
-        import torch
-        
-        # Load model
-        self.model = FusionModel(role=ModelRole.REPLAY_ONLY)
-        if model_path:
-            self.model.load_state_dict(torch.load(model_path))
-            self.model.eval()
-    
-    def predict(self, features):
-        import torch
-        from src.core.enums import RunMode
-        
-        # Extract features
-        x_1m = torch.tensor(features['x_price_1m'], dtype=torch.float32).unsqueeze(0)
-        x_5m = torch.tensor(features['x_price_5m'], dtype=torch.float32).unsqueeze(0)
-        x_15m = torch.tensor(features['x_price_15m'], dtype=torch.float32).unsqueeze(0)
-        x_context = torch.tensor(features['x_context'], dtype=torch.float32).unsqueeze(0)
-        
-        with torch.no_grad():
-            logits = self.model(x_1m, x_5m, x_15m, x_context, run_mode=RunMode.REPLAY)
-            probs = torch.softmax(logits, dim=1)
-        
-        return {
-            'logits': logits[0].numpy().tolist(),
-            'probs': probs[0].numpy().tolist(),
-        }
-
-
-# Auto-register on import
-def register_all_models():
-    """
-    Register all available models.
-    Call this at startup to populate the registry.
-    """
-    pass
-
-
-@ModelRegistry.register(
-    model_id="ifvg_4class",
-    name="IFVG 4-Class CNN",
-    description="4-class CNN for IFVG pattern detection (LONG_WIN, LONG_LOSS, SHORT_WIN, SHORT_LOSS)",
-    input_schema={
-        "ohlcv": {"type": "array", "shape": [5, 30], "normalization": "percent_change"},
-    },
-    output_schema={
-        "probs": {"type": "array", "shape": [4]},  # [LONG_WIN, LONG_LOSS, SHORT_WIN, SHORT_LOSS]
-    }
-)
-class IFVG4ClassWrapper:
-    """Wrapper for IFVG4ClassCNN."""
-    
-    def __init__(self, model_path: str = None, **kwargs):
-        import torch
-        import torch.nn as nn
-        
-        # Define architecture inline (same as train_ifvg_4class.py)
-        class IFVG4ClassCNN(nn.Module):
-            def __init__(self, input_channels=5, seq_length=30, num_classes=4):
-                super().__init__()
-                self.features = nn.Sequential(
-                    nn.Conv1d(input_channels, 32, kernel_size=3, padding=1),
-                    nn.BatchNorm1d(32),
-                    nn.ReLU(),
-                    nn.MaxPool1d(2),
-                    nn.Conv1d(32, 64, kernel_size=3, padding=1),
-                    nn.BatchNorm1d(64),
-                    nn.ReLU(),
-                    nn.MaxPool1d(2),
-                    nn.Conv1d(64, 128, kernel_size=3, padding=1),
-                    nn.BatchNorm1d(128),
-                    nn.ReLU(),
-                    nn.AdaptiveAvgPool1d(1),
-                )
-                self.classifier = nn.Sequential(
-                    nn.Flatten(),
-                    nn.Linear(128, 64),
-                    nn.ReLU(),
-                    nn.Dropout(0.4),
-                    nn.Linear(64, 32),
-                    nn.ReLU(),
-                    nn.Dropout(0.3),
-                    nn.Linear(32, num_classes),
-                )
-            
-            def forward(self, x):
-                x = self.features(x)
-                return self.classifier(x)
-        
-        self.model = IFVG4ClassCNN(**kwargs)
-        if model_path:
-            state = torch.load(model_path, map_location='cpu', weights_only=False)
-            # Handle both raw state_dict and checkpoint bundles
-            if 'model_state_dict' in state:
-                self.model.load_state_dict(state['model_state_dict'])
-            else:
-                self.model.load_state_dict(state)
-        self.model.eval()
-    
-    def predict(self, features):
-        import torch
-        
-        # Expects features['ohlcv'] as (5, 30) normalized array
-        x = torch.tensor(features['ohlcv'], dtype=torch.float32).unsqueeze(0)
-        
-        with torch.no_grad():
-            logits = self.model(x)
-            probs = torch.softmax(logits, dim=1)
-        
-        probs_list = probs[0].numpy().tolist()
-        
-        # Determine triggered direction
-        long_win, long_loss, short_win, short_loss = probs_list
-        
-        return {
-            'probs': probs_list,
-            'long_win_prob': long_win,
-            'short_win_prob': short_win,
-            'direction': 'LONG' if long_win > short_win else 'SHORT',
-            'triggered': True,  # Always true - let caller apply threshold
-        }
-
diff --git a/src/policy/scanner_registry_init.py b/src/policy/scanner_registry_init.py
deleted file mode 100644
index 2b1a184..0000000
--- a/src/policy/scanner_registry_init.py
+++ /dev/null
@@ -1,103 +0,0 @@
-"""
-Scanner Registration
-Wire existing scanners into the ScannerRegistry.
-"""
-
-from src.core.registries import ScannerRegistry
-from src.policy.scanners import AlwaysScanner, IntervalScanner
-from src.policy.modular_scanner import ModularScanner
-
-
-# =============================================================================
-# Register built-in scanners
-# =============================================================================
-
-@ScannerRegistry.register(
-    scanner_id="always",
-    name="Always Scanner",
-    description="Triggers on every bar - useful for testing or fixed strategies",
-    params_schema={}
-)
-class AlwaysScannerWrapper:
-    """Wrapper to adapt AlwaysScanner to registry."""
-    def __init__(self):
-        self._scanner = AlwaysScanner()
-    
-    def scan(self, step_result):
-        # Adapt to registry interface
-        # In real use, would extract state and features from step_result
-        from src.policy.scanners import ScannerResult
-        return ScannerResult(
-            scanner_id="always",
-            triggered=True,
-            score=1.0
-        )
-
-
-@ScannerRegistry.register(
-    scanner_id="interval",
-    name="Interval Scanner",
-    description="Triggers every N bars",
-    params_schema={
-        "interval": {"type": "integer", "default": 5, "min": 1}
-    }
-)
-class IntervalScannerWrapper:
-    """Wrapper to adapt IntervalScanner to registry."""
-    def __init__(self, interval: int = 5):
-        self._scanner = IntervalScanner(interval=interval)
-    
-    def scan(self, step_result):
-        from src.policy.scanners import ScannerResult
-        # Simplified - real implementation would extract features
-        return ScannerResult(
-            scanner_id=f"interval_{self._scanner.interval}",
-            triggered=False,  # Placeholder
-            score=0.0
-        )
-
-
-@ScannerRegistry.register(
-    scanner_id="modular",
-    name="Modular Scanner",
-    description="Scanner based on composable triggers (time, candle patterns, indicators)",
-    params_schema={
-        "trigger_config": {
-            "type": "object",
-            "description": "Trigger configuration dict",
-            "required": True
-        },
-        "cooldown_bars": {
-            "type": "integer",
-            "default": 20,
-            "min": 0
-        }
-    }
-)
-class ModularScannerWrapper:
-    """Wrapper to adapt ModularScanner to registry."""
-    def __init__(self, trigger_config: dict, cooldown_bars: int = 20):
-        self._scanner = ModularScanner(
-            trigger_config=trigger_config,
-            cooldown_bars=cooldown_bars
-        )
-    
-    def scan(self, step_result):
-        from src.policy.scanners import ScannerResult
-        # Simplified - real implementation would extract features
-        return ScannerResult(
-            scanner_id=self._scanner.scanner_id,
-            triggered=False,  # Placeholder
-            score=0.0
-        )
-
-
-# Auto-register on import
-def register_all_scanners():
-    """
-    Register all available scanners.
-    Call this at startup to populate the registry.
-    """
-    # The decorators above already registered them
-    # This function just serves as a hook for explicit initialization
-    pass
diff --git a/src/server/main.py b/src/server/main.py
index 39320af..285900f 100644
--- a/src/server/main.py
+++ b/src/server/main.py
@@ -394,7 +394,6 @@ AVAILABLE ACTIONS:
 3. Load run: ACTION: {{"type": "LOAD_RUN", "payload": "<run_id>"}}
 4. RUN STRATEGY: ACTION: {{"type": "RUN_STRATEGY", "payload": {{"strategy": "modular", "config": <config_dict>}}}}
 5. START REPLAY: ACTION: {{"type": "START_REPLAY", "payload": {{"start_date": "YYYY-MM-DD", "days": 1, "speed": 10, "threshold": 0.6}}}}
-6. TRAIN FROM SCAN: ACTION: {{"type": "TRAIN_FROM_SCAN", "payload": {{"scan_run_id": "<run_id>", "model_name": "my_model"}}}}
 
 MODULAR STRATEGY FORMAT:
 {{
@@ -595,215 +594,15 @@ async def run_strategy(request: RunStrategyRequest) -> Dict[str, Any]:
         return {"success": False, "error": str(e)}
 
 
-# =============================================================================
-# ENDPOINTS: Agent Training (Train CNN from Scan Results)
-# =============================================================================
-
-class TrainFromScanRequest(BaseModel):
-    """Request to train a CNN from scan results."""
-    scan_run_id: str  # Run ID containing scan results (records.jsonl)
-    model_name: Optional[str] = None  # Output model name (auto-generated if not provided)
-    lookback_bars: int = 30  # Number of bars before each hit to train on
-    epochs: int = 50
-    batch_size: int = 16
-
-
-@app.post("/agent/train-from-scan")
-async def train_from_scan(request: TrainFromScanRequest) -> Dict[str, Any]:
-    """
-    Train a 4-class CNN from scan results.
-    
-    This enables the agent to:
-    1. Run a scan to find patterns
-    2. Call this endpoint to train a model
-    3. Use the model in simulation mode
-    
-    The model learns to predict LONG_WIN, LONG_LOSS, SHORT_WIN, SHORT_LOSS
-    from the N bars before each scan hit.
-    """
-    import subprocess
-    from datetime import datetime
-    
-    # Find the run directory
-    run_dir = find_run_dir(request.scan_run_id)
-    if not run_dir:
-        return {"success": False, "error": f"Scan run '{request.scan_run_id}' not found"}
-    
-    # Find records file
-    records_file = find_jsonl_file(run_dir, ["records.jsonl", "decisions.jsonl"])
-    if not records_file:
-        return {"success": False, "error": f"No records.jsonl in run '{request.scan_run_id}'"}
-    
-    # Generate model name
-    model_name = request.model_name or f"cnn_{request.scan_run_id}_{datetime.now().strftime('%H%M%S')}"
-    model_path = Path("models") / f"{model_name}.pth"
-    
-    # Build training command
-    cmd = [
-        "python", "-c", f"""
-import sys
-sys.path.insert(0, '.')
-from scripts.train_ifvg_4class import IFVG4ClassCNN, IFVG4ClassDataset, train_model
-import json
-import torch
-from torch.utils.data import DataLoader, random_split
-from pathlib import Path
-
-# Load records
-records = []
-with open('{records_file}') as f:
-    for line in f:
-        records.append(json.loads(line))
-print(f"Loaded {{len(records)}} records")
-
-# Create dataset
-dataset = IFVG4ClassDataset(records, lookback={request.lookback_bars})
-if len(dataset) < 10:
-    print("ERROR: Not enough samples")
-    sys.exit(1)
-
-# Split
-train_size = int(0.8 * len(dataset))
-val_size = len(dataset) - train_size
-train_ds, val_ds = random_split(dataset, [train_size, val_size])
-train_loader = DataLoader(train_ds, batch_size={request.batch_size}, shuffle=True)
-val_loader = DataLoader(val_ds, batch_size={request.batch_size})
-
-# Train
-model = IFVG4ClassCNN()
-device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
-best_state, best_acc = train_model(model, train_loader, val_loader, {request.epochs}, 0.001, device)
-
-# Save
-Path('models').mkdir(exist_ok=True)
-torch.save(best_state, '{model_path}')
-print(f"Saved model to {model_path}")
-print(f"Accuracy: {{best_acc:.2%}}")
-"""
-    ]
-    
-    try:
-        result = subprocess.run(
-            cmd,
-            cwd=str(Path(__file__).parent.parent.parent),
-            capture_output=True,
-            text=True,
-            timeout=300  # 5 min timeout for training
-        )
-        
-        if result.returncode == 0:
-            return {
-                "success": True,
-                "model_path": str(model_path),
-                "message": f"Trained model from {request.scan_run_id}. Model saved to '{model_path}'.",
-                "output": result.stdout[-500:] if result.stdout else ""
-            }
-        else:
-            return {
-                "success": False,
-                "error": result.stderr[-500:] if result.stderr else result.stdout[-500:] if result.stdout else "Unknown error"
-            }
-    except subprocess.TimeoutExpired:
-        return {"success": False, "error": "Training timed out (>5 min)"}
-    except Exception as e:
-        return {"success": False, "error": str(e)}
-
-# =============================================================================
-# ENDPOINTS: Experiment Database (Agent Memory)
-# =============================================================================
-
-@app.get("/experiments")
-async def list_experiments(
-    strategy: Optional[str] = Query(None),
-    min_trades: int = Query(10),
-    limit: int = Query(20)
-) -> Dict[str, Any]:
-    """List experiments, optionally filtered by strategy."""
-    from src.storage import ExperimentDB
-    
-    db = ExperimentDB()
-    
-    if strategy:
-        results = db.query_best("created_at", strategy=strategy, min_trades=min_trades, top_k=limit)
-    else:
-        results = db.query_best("created_at", min_trades=min_trades, top_k=limit)
-    
-    return {
-        "count": len(results),
-        "experiments": results
-    }
-
-
-@app.get("/experiments/best")
-async def get_best_experiments(
-    metric: str = Query("win_rate"),
-    strategy: Optional[str] = Query(None),
-    min_trades: int = Query(10),
-    top_k: int = Query(5)
-) -> Dict[str, Any]:
-    """
-    Get best experiments by metric.
-    
-    Metrics: win_rate, total_pnl, sharpe, profit_factor
-    """
-    from src.storage import ExperimentDB
-    
-    db = ExperimentDB()
-    results = db.query_best(metric, strategy=strategy, min_trades=min_trades, top_k=top_k)
-    
-    return {
-        "metric": metric,
-        "count": len(results),
-        "best": results
-    }
-
-
-@app.get("/experiments/strategies")
-async def list_strategies() -> Dict[str, Any]:
-    """List all strategies with aggregated stats."""
-    from src.storage import ExperimentDB
-    
-    db = ExperimentDB()
-    strategies = db.list_strategies()
-    
-    return {
-        "count": len(strategies),
-        "strategies": strategies
-    }
-
-
-@app.post("/experiments/store")
-async def store_experiment(
-    run_id: str,
-    strategy: str,
-    config: Dict[str, Any],
-    metrics: Dict[str, Any],
-    model_path: Optional[str] = None
-) -> Dict[str, Any]:
-    """Store experiment results."""
-    from src.storage import ExperimentDB
-    
-    db = ExperimentDB()
-    success = db.store_run(run_id, strategy, config, metrics, model_path)
-    
-    return {"success": success, "run_id": run_id}
-
-
 # =============================================================================
 # HEALTH CHECK
 # =============================================================================
 
 @app.get("/health")
 async def health():
-    from src.storage import ExperimentDB
-    
     runs = await list_runs()
-    db = ExperimentDB()
-    
     return {
         "status": "ok", 
         "results_dir": str(RESULTS_DIR),
-        "available_runs": runs,
-        "experiments_count": db.count()
+        "available_runs": runs
     }
-
diff --git a/src/sim/account_manager.py b/src/sim/account_manager.py
deleted file mode 100644
index 522f64d..0000000
--- a/src/sim/account_manager.py
+++ /dev/null
@@ -1,149 +0,0 @@
-"""
-Account Manager
-Multi-account simulation tracking.
-"""
-
-from typing import Dict, List, Optional
-from dataclasses import dataclass, field
-import pandas as pd
-
-from src.sim.account import Account, TradeRecord
-from src.sim.costs import CostModel, DEFAULT_COSTS
-from src.sim.execution import Fill
-
-
-@dataclass
-class AccountSnapshot:
-    """Snapshot of account state at a point in time."""
-    account_id: str
-    timestamp: pd.Timestamp
-    balance: float
-    equity: float
-    realized_pnl: float
-    unrealized_pnl: float
-    open_positions: int
-    total_trades: int
-    
-    def to_dict(self) -> Dict:
-        return {
-            'account_id': self.account_id,
-            'timestamp': self.timestamp.isoformat() if self.timestamp else None,
-            'balance': self.balance,
-            'equity': self.equity,
-            'realized_pnl': self.realized_pnl,
-            'unrealized_pnl': self.unrealized_pnl,
-            'open_positions': self.open_positions,
-            'total_trades': self.total_trades,
-        }
-
-
-class AccountManager:
-    """
-    Multi-account manager for simulation.
-    
-    Manages multiple accounts, routes orders, aggregates PnL.
-    Useful for:
-    - Multiple strategies in one session
-    - Different risk profiles
-    - Prop firm rule testing (per-account limits)
-    """
-    
-    def __init__(self):
-        self.accounts: Dict[str, Account] = {}
-        self.snapshots: List[AccountSnapshot] = []
-        
-    def create_account(
-        self,
-        account_id: str,
-        starting_balance: float = 50000.0,
-        costs: CostModel = None
-    ) -> Account:
-        """Create a new account."""
-        if account_id in self.accounts:
-            raise ValueError(f"Account {account_id} already exists")
-        
-        account = Account(
-            starting_balance=starting_balance,
-            costs=costs or DEFAULT_COSTS
-        )
-        self.accounts[account_id] = account
-        return account
-    
-    def delete_account(self, account_id: str):
-        """Delete an account."""
-        if account_id in self.accounts:
-            del self.accounts[account_id]
-    
-    def get_account(self, account_id: str) -> Optional[Account]:
-        """Get account by ID."""
-        return self.accounts.get(account_id)
-    
-    def list_accounts(self) -> List[str]:
-        """List all account IDs."""
-        return list(self.accounts.keys())
-    
-    def take_snapshot(self, account_id: str, current_price: float, timestamp: pd.Timestamp):
-        """Take a snapshot of account state."""
-        account = self.accounts.get(account_id)
-        if not account:
-            return
-        
-        equity = account.get_equity(current_price)
-        unrealized = equity - account.balance
-        
-        snapshot = AccountSnapshot(
-            account_id=account_id,
-            timestamp=timestamp,
-            balance=account.balance,
-            equity=equity,
-            realized_pnl=account.realized_pnl,
-            unrealized_pnl=unrealized,
-            open_positions=len(account.positions),
-            total_trades=len(account.trades),
-        )
-        self.snapshots.append(snapshot)
-        return snapshot
-    
-    def get_total_pnl(self) -> float:
-        """Get total PnL across all accounts."""
-        return sum(acc.realized_pnl for acc in self.accounts.values())
-    
-    def get_total_equity(self, current_price: float) -> float:
-        """Get total equity across all accounts."""
-        return sum(acc.get_equity(current_price) for acc in self.accounts.values())
-    
-    def get_aggregate_stats(self) -> Dict:
-        """Get aggregated stats across all accounts."""
-        total_trades = sum(len(acc.trades) for acc in self.accounts.values())
-        total_pnl = self.get_total_pnl()
-        
-        all_trades = []
-        for acc in self.accounts.values():
-            all_trades.extend(acc.trades)
-        
-        wins = sum(1 for t in all_trades if t.outcome == 'WIN')
-        
-        return {
-            'total_accounts': len(self.accounts),
-            'total_trades': total_trades,
-            'wins': wins,
-            'losses': total_trades - wins,
-            'win_rate': wins / total_trades if total_trades > 0 else 0.0,
-            'total_pnl': total_pnl,
-            'avg_pnl_per_trade': total_pnl / total_trades if total_trades > 0 else 0.0,
-        }
-    
-    def reset_all(self):
-        """Reset all accounts to starting state."""
-        for account in self.accounts.values():
-            account.balance = account.starting_balance
-            account.positions.clear()
-            account.trades.clear()
-            account.realized_pnl = 0.0
-            account.peak_balance = account.starting_balance
-            account.max_drawdown = 0.0
-        self.snapshots.clear()
-    
-    def get_snapshots_for_account(self, account_id: str) -> List[AccountSnapshot]:
-        """Get all snapshots for a specific account."""
-        return [s for s in self.snapshots if s.account_id == account_id]
diff --git a/src/sim/simulation_session.py b/src/sim/simulation_session.py
deleted file mode 100644
index a083035..0000000
--- a/src/sim/simulation_session.py
+++ /dev/null
@@ -1,296 +0,0 @@
-"""
-Simulation Session
-Backend-owned simulation stepping with events.
-
-This is the backend counterpart to the frontend SimulationView.
-Instead of the frontend doing stepping, the backend owns:
-- MarketStepper
-- Indicator pipeline
-- Policies/models
-- Accounts
-- OCO engine
-
-Frontend becomes: renderer + controls + config UI
-"""
-
-from dataclasses import dataclass, field
-from typing import Optional, List, Dict, Any, Iterator
-from enum import Enum
-import pandas as pd
-from pathlib import Path
-
-from src.sim.stepper import MarketStepper
-from src.sim.account_manager import AccountManager
-from src.core.enums import RunMode
-from src.core.registries import IndicatorSeries, IndicatorRegistry
-
-
-class SimEventType(Enum):
-    """Types of events during simulation."""
-    BAR = "BAR"                          # New bar arrived
-    INDICATORS = "INDICATORS"            # Indicators computed
-    DECISION = "DECISION"                # Decision point triggered
-    ORDER_SUBMIT = "ORDER_SUBMIT"        # Order submitted
-    FILL = "FILL"                        # Order filled
-    POSITION_OPEN = "POSITION_OPEN"      # Position opened
-    POSITION_CLOSE = "POSITION_CLOSE"    # Position closed
-    ACCOUNT_UPDATE = "ACCOUNT_UPDATE"    # Account state changed
-    SESSION_START = "SESSION_START"      # Session started
-    SESSION_END = "SESSION_END"          # Session ended
-
-
-@dataclass
-class SimEvent:
-    """Single event during simulation."""
-    type: SimEventType
-    timestamp: pd.Timestamp
-    bar_idx: int
-    data: Dict[str, Any] = field(default_factory=dict)
-    
-    def to_dict(self) -> Dict[str, Any]:
-        return {
-            'type': self.type.value,
-            'timestamp': self.timestamp.isoformat() if self.timestamp else None,
-            'bar_idx': self.bar_idx,
-            'data': self.data,
-        }
-
-
-class SimulationSession:
-    """
-    Backend simulation session.
-    
-    Owns all simulation state:
-    - Market stepper
-    - Indicator cache
-    - Active accounts
-    - Active policies (scanners/models)
-    - Emits structured events
-    
-    Frontend subscribes to events via SSE.
-    """
-    
-    def __init__(
-        self,
-        df: pd.DataFrame,
-        session_id: str = "default",
-        start_idx: int = 0,
-        end_idx: Optional[int] = None,
-    ):
-        """
-        Initialize simulation session.
-        
-        Args:
-            df: Full OHLCV DataFrame
-            session_id: Unique session identifier
-            start_idx: Starting bar index
-            end_idx: Ending bar index (None = end of df)
-        """
-        self.session_id = session_id
-        self.df = df
-        self.start_idx = start_idx
-        self.end_idx = end_idx or len(df)
-        
-        # Market stepper
-        self.stepper = MarketStepper(df, start_idx=start_idx, end_idx=self.end_idx)
-        
-        # Account manager
-        self.account_manager = AccountManager()
-        
-        # Indicators (computed on demand, cached)
-        self.indicator_cache: Dict[str, IndicatorSeries] = {}
-        self.enabled_indicators: List[str] = []
-        
-        # Policies (scanners/models)
-        self.active_scanners: List[Any] = []
-        self.active_models: List[Any] = []
-        
-        # Event log
-        self.events: List[SimEvent] = []
-        
-        # Session state
-        self.is_running = False
-        self.is_paused = False
-        self.current_bar_idx: Optional[int] = None
-        self.current_timestamp: Optional[pd.Timestamp] = None
-    
-    def add_account(self, account_id: str, starting_balance: float = 50000.0):
-        """Add an account to the session."""
-        self.account_manager.create_account(account_id, starting_balance)
-    
-    def enable_indicator(self, indicator_id: str):
-        """Enable an indicator for computation."""
-        if indicator_id not in self.enabled_indicators:
-            self.enabled_indicators.append(indicator_id)
-    
-    def disable_indicator(self, indicator_id: str):
-        """Disable an indicator."""
-        if indicator_id in self.enabled_indicators:
-            self.enabled_indicators.remove(indicator_id)
-    
-    def add_scanner(self, scanner: Any):
-        """Add a scanner to active scanners."""
-        self.active_scanners.append(scanner)
-    
-    def add_model(self, model: Any):
-        """Add a model to active models."""
-        self.active_models.append(model)
-    
-    def start(self):
-        """Start the session."""
-        self.is_running = True
-        self.is_paused = False
-        
-        # Emit session start event
-        event = SimEvent(
-            type=SimEventType.SESSION_START,
-            timestamp=self.df.iloc[self.start_idx]['time'],
-            bar_idx=self.start_idx,
-            data={
-                'session_id': self.session_id,
-                'accounts': self.account_manager.list_accounts(),
-                'indicators': self.enabled_indicators,
-            }
-        )
-        self.events.append(event)
-        return event
-    
-    def stop(self):
-        """Stop the session."""
-        self.is_running = False
-        
-        # Emit session end event
-        if self.current_timestamp and self.current_bar_idx is not None:
-            event = SimEvent(
-                type=SimEventType.SESSION_END,
-                timestamp=self.current_timestamp,
-                bar_idx=self.current_bar_idx,
-                data={
-                    'session_id': self.session_id,
-                    'total_events': len(self.events),
-                    'stats': self.account_manager.get_aggregate_stats(),
-                }
-            )
-            self.events.append(event)
-            return event
-    
-    def pause(self):
-        """Pause the session."""
-        self.is_paused = True
-    
-    def resume(self):
-        """Resume the session."""
-        self.is_paused = False
-    
-    def step_once(self) -> Optional[List[SimEvent]]:
-        """
-        Step forward by one bar.
-        
-        Returns list of events generated by this step.
-        """
-        if not self.is_running or self.is_paused:
-            return None
-        
-        step = self.stepper.step()
-        if step.is_done:
-            return None
-        
-        self.current_bar_idx = step.bar_idx
-        self.current_timestamp = step.bar['time']
-        
-        events = []
-        
-        # 1. BAR event
-        bar_event = SimEvent(
-            type=SimEventType.BAR,
-            timestamp=self.current_timestamp,
-            bar_idx=self.current_bar_idx,
-            data={
-                'open': float(step.bar['open']),
-                'high': float(step.bar['high']),
-                'low': float(step.bar['low']),
-                'close': float(step.bar['close']),
-                'volume': float(step.bar['volume']),
-            }
-        )
-        events.append(bar_event)
-        
-        # 2. INDICATORS event (if any enabled)
-        if self.enabled_indicators:
-            # Compute indicators (in real implementation, would use IndicatorRegistry)
-            indicators_data = {}
-            for ind_id in self.enabled_indicators:
-                # Placeholder - real implementation would compute
-                indicators_data[ind_id] = None
-            
-            ind_event = SimEvent(
-                type=SimEventType.INDICATORS,
-                timestamp=self.current_timestamp,
-                bar_idx=self.current_bar_idx,
-                data={'indicators': indicators_data}
-            )
-            events.append(ind_event)
-        
-        # 3. Check scanners/policies for DECISION events
-        # (Placeholder - real implementation would run scanners)
-        
-        # 4. Update accounts with current price
-        current_price = float(step.bar['close'])
-        for account_id in self.account_manager.list_accounts():
-            snapshot = self.account_manager.take_snapshot(
-                account_id,
-                current_price,
-                self.current_timestamp
-            )
-            if snapshot:
-                acc_event = SimEvent(
-                    type=SimEventType.ACCOUNT_UPDATE,
-                    timestamp=self.current_timestamp,
-                    bar_idx=self.current_bar_idx,
-                    data=snapshot.to_dict()
-                )
-                events.append(acc_event)
-        
-        # Store events
-        self.events.extend(events)
-        return events
-    
-    def play(self) -> Iterator[SimEvent]:
-        """
-        Play through the session, yielding events.
-        
-        This is the main simulation loop for SSE streaming.
-        """
-        self.start()
-        
-        while self.is_running:
-            # Wait if paused
-            if self.is_paused:
-                break
-            
-            events = self.step_once()
-            if not events:
-                # Session is done
-                break
-            
-            for event in events:
-                yield event
-        
-        # Emit end event
-        end_event = self.stop()
-        if end_event:
-            yield end_event
-    
-    def get_state(self) -> Dict[str, Any]:
-        """Get current session state."""
-        return {
-            'session_id': self.session_id,
-            'is_running': self.is_running,
-            'is_paused': self.is_paused,
-            'current_bar_idx': self.current_bar_idx,
-            'current_timestamp': self.current_timestamp.isoformat() if self.current_timestamp else None,
-            'total_events': len(self.events),
-            'accounts': self.account_manager.list_accounts(),
-            'enabled_indicators': self.enabled_indicators,
-            'stats': self.account_manager.get_aggregate_stats(),
-        }
diff --git a/src/storage/__init__.py b/src/storage/__init__.py
deleted file mode 100644
index 2af58ef..0000000
--- a/src/storage/__init__.py
+++ /dev/null
@@ -1,9 +0,0 @@
-"""
-Storage module for MLang2.
-
-Provides experiment database and result management.
-"""
-
-from src.storage.experiments_db import ExperimentDB, ExperimentRecord
-
-__all__ = ['ExperimentDB', 'ExperimentRecord']
diff --git a/src/storage/experiments_db.py b/src/storage/experiments_db.py
deleted file mode 100644
index 1c4b75b..0000000
--- a/src/storage/experiments_db.py
+++ /dev/null
@@ -1,287 +0,0 @@
-"""
-Experiment Database
-
-SQLite-backed storage for experiment results.
-Enables the agent to query past performance and find optimal configurations.
-
-Usage:
-    from src.storage.experiments_db import ExperimentDB
-    
-    db = ExperimentDB()
-    db.store_run(run_id, metrics)
-    best = db.query_best("win_rate", top_k=5)
-"""
-
-import sqlite3
-import json
-from pathlib import Path
-from typing import Dict, Any, List, Optional
-from dataclasses import dataclass, field
-from datetime import datetime
-
-
-@dataclass
-class ExperimentRecord:
-    """Single experiment record."""
-    run_id: str
-    created_at: str
-    strategy: str
-    model_path: Optional[str]
-    config: Dict[str, Any]
-    
-    # Key metrics
-    total_trades: int
-    wins: int
-    losses: int
-    win_rate: float
-    total_pnl: float
-    avg_pnl_per_trade: float
-    
-    # Optional extended metrics
-    sharpe: Optional[float] = None
-    max_drawdown: Optional[float] = None
-    profit_factor: Optional[float] = None
-    
-    def to_dict(self) -> Dict:
-        return {
-            'run_id': self.run_id,
-            'created_at': self.created_at,
-            'strategy': self.strategy,
-            'model_path': self.model_path,
-            'config': self.config,
-            'total_trades': self.total_trades,
-            'wins': self.wins,
-            'losses': self.losses,
-            'win_rate': self.win_rate,
-            'total_pnl': self.total_pnl,
-            'avg_pnl_per_trade': self.avg_pnl_per_trade,
-            'sharpe': self.sharpe,
-            'max_drawdown': self.max_drawdown,
-            'profit_factor': self.profit_factor,
-        }
-
-
-class ExperimentDB:
-    """
-    SQLite database for experiment results.
-    
-    Allows the agent to:
-    - Store run results
-    - Query best configurations by metric
-    - Compare strategies
-    - Learn from history
-    """
-    
-    def __init__(self, db_path: str = "results/experiments.db"):
-        self.db_path = Path(db_path)
-        self.db_path.parent.mkdir(parents=True, exist_ok=True)
-        self._init_db()
-    
-    def _init_db(self):
-        """Initialize database schema."""
-        conn = sqlite3.connect(self.db_path)
-        cursor = conn.cursor()
-        
-        cursor.execute("""
-            CREATE TABLE IF NOT EXISTS experiments (
-                id INTEGER PRIMARY KEY AUTOINCREMENT,
-                run_id TEXT UNIQUE NOT NULL,
-                created_at TEXT NOT NULL,
-                strategy TEXT NOT NULL,
-                model_path TEXT,
-                config_json TEXT NOT NULL,
-                
-                total_trades INTEGER NOT NULL,
-                wins INTEGER NOT NULL,
-                losses INTEGER NOT NULL,
-                win_rate REAL NOT NULL,
-                total_pnl REAL NOT NULL,
-                avg_pnl_per_trade REAL NOT NULL,
-                
-                sharpe REAL,
-                max_drawdown REAL,
-                profit_factor REAL
-            )
-        """)
-        
-        # Create indexes for common queries
-        cursor.execute("CREATE INDEX IF NOT EXISTS idx_strategy ON experiments(strategy)")
-        cursor.execute("CREATE INDEX IF NOT EXISTS idx_win_rate ON experiments(win_rate DESC)")
-        cursor.execute("CREATE INDEX IF NOT EXISTS idx_total_pnl ON experiments(total_pnl DESC)")
-        cursor.execute("CREATE INDEX IF NOT EXISTS idx_created ON experiments(created_at DESC)")
-        
-        conn.commit()
-        conn.close()
-    
-    def store_run(
-        self,
-        run_id: str,
-        strategy: str,
-        config: Dict[str, Any],
-        metrics: Dict[str, Any],
-        model_path: Optional[str] = None
-    ) -> bool:
-        """
-        Store experiment results.
-        
-        Args:
-            run_id: Unique run identifier
-            strategy: Strategy name (e.g., "opening_range", "modular")
-            config: Run configuration dict
-            metrics: Must include: total_trades, wins, losses, win_rate, total_pnl
-            model_path: Path to model file if applicable
-        
-        Returns:
-            True if stored successfully
-        """
-        conn = sqlite3.connect(self.db_path)
-        cursor = conn.cursor()
-        
-        try:
-            cursor.execute("""
-                INSERT OR REPLACE INTO experiments (
-                    run_id, created_at, strategy, model_path, config_json,
-                    total_trades, wins, losses, win_rate, total_pnl, avg_pnl_per_trade,
-                    sharpe, max_drawdown, profit_factor
-                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
-            """, (
-                run_id,
-                datetime.utcnow().isoformat() + 'Z',
-                strategy,
-                model_path,
-                json.dumps(config),
-                metrics.get('total_trades', metrics.get('trades', 0)),
-                metrics.get('wins', 0),
-                metrics.get('losses', 0),
-                metrics.get('win_rate', 0.0),
-                metrics.get('total_pnl', 0.0),
-                metrics.get('avg_pnl_per_trade', 0.0),
-                metrics.get('sharpe'),
-                metrics.get('max_drawdown'),
-                metrics.get('profit_factor'),
-            ))
-            conn.commit()
-            return True
-        except Exception as e:
-            print(f"Error storing experiment: {e}")
-            return False
-        finally:
-            conn.close()
-    
-    def query_best(
-        self,
-        metric: str = "win_rate",
-        strategy: Optional[str] = None,
-        min_trades: int = 10,
-        top_k: int = 5
-    ) -> List[Dict]:
-        """
-        Query best experiments by metric.
-        
-        Args:
-            metric: Column to sort by (win_rate, total_pnl, sharpe, etc.)
-            strategy: Filter by strategy name
-            min_trades: Minimum trades required
-            top_k: Number of results
-        
-        Returns:
-            List of experiment dicts
-        """
-        conn = sqlite3.connect(self.db_path)
-        conn.row_factory = sqlite3.Row
-        cursor = conn.cursor()
-        
-        query = f"""
-            SELECT * FROM experiments
-            WHERE total_trades >= ?
-            {"AND strategy = ?" if strategy else ""}
-            ORDER BY {metric} DESC
-            LIMIT ?
-        """
-        
-        params = [min_trades]
-        if strategy:
-            params.append(strategy)
-        params.append(top_k)
-        
-        cursor.execute(query, params)
-        rows = cursor.fetchall()
-        conn.close()
-        
-        results = []
-        for row in rows:
-            record = dict(row)
-            record['config'] = json.loads(record['config_json'])
-            del record['config_json']
-            results.append(record)
-        
-        return results
-    
-    def get_run(self, run_id: str) -> Optional[Dict]:
-        """Get a specific run by ID."""
-        conn = sqlite3.connect(self.db_path)
-        conn.row_factory = sqlite3.Row
-        cursor = conn.cursor()
-        
-        cursor.execute("SELECT * FROM experiments WHERE run_id = ?", (run_id,))
-        row = cursor.fetchone()
-        conn.close()
-        
-        if row:
-            record = dict(row)
-            record['config'] = json.loads(record['config_json'])
-            del record['config_json']
-            return record
-        return None
-    
-    def list_strategies(self) -> List[Dict]:
-        """List all strategies with their stats."""
-        conn = sqlite3.connect(self.db_path)
-        cursor = conn.cursor()
-        
-        cursor.execute("""
-            SELECT 
-                strategy,
-                COUNT(*) as run_count,
-                AVG(win_rate) as avg_win_rate,
-                AVG(total_pnl) as avg_pnl,
-                MAX(win_rate) as best_win_rate,
-                MAX(total_pnl) as best_pnl
-            FROM experiments
-            GROUP BY strategy
-            ORDER BY run_count DESC
-        """)
-        
-        rows = cursor.fetchall()
-        conn.close()
-        
-        return [
-            {
-                'strategy': row[0],
-                'run_count': row[1],
-                'avg_win_rate': row[2],
-                'avg_pnl': row[3],
-                'best_win_rate': row[4],
-                'best_pnl': row[5],
-            }
-            for row in rows
-        ]
-    
-    def count(self) -> int:
-        """Get total number of experiments."""
-        conn = sqlite3.connect(self.db_path)
-        cursor = conn.cursor()
-        cursor.execute("SELECT COUNT(*) FROM experiments")
-        count = cursor.fetchone()[0]
-        conn.close()
-        return count
-    
-    def delete_run(self, run_id: str) -> bool:
-        """Delete a run by ID."""
-        conn = sqlite3.connect(self.db_path)
-        cursor = conn.cursor()
-        cursor.execute("DELETE FROM experiments WHERE run_id = ?", (run_id,))
-        deleted = cursor.rowcount > 0
-        conn.commit()
-        conn.close()
-        return deleted
diff --git a/tests/test_backend_simulation.py b/tests/test_backend_simulation.py
deleted file mode 100644
index ff76af8..0000000
--- a/tests/test_backend_simulation.py
+++ /dev/null
@@ -1,288 +0,0 @@
-#!/usr/bin/env python3
-"""
-Backend Simulation Test
-
-Mirrors what the frontend SimulationView does:
-1. Load market data
-2. Step through bars
-3. Call CNN inference every N bars
-4. Manage OCO brackets (entry, SL, TP)
-5. Track wins/losses
-
-Run:
-    python tests/test_backend_simulation.py
-"""
-
-import sys
-from pathlib import Path
-sys.path.insert(0, str(Path(__file__).parent.parent))
-
-import json
-import numpy as np
-from dataclasses import dataclass
-from typing import Optional, List, Dict
-
-
-@dataclass
-class OCOBracket:
-    """OCO bracket tracking - same as frontend."""
-    entry: float
-    stop: float
-    tp: float
-    start_time: float
-    direction: str  # 'LONG' or 'SHORT'
-
-
-@dataclass
-class Trade:
-    """Completed trade record."""
-    entry: float
-    exit: float
-    direction: str
-    outcome: str  # 'WIN' or 'LOSS'
-    bars_held: int
-    pnl: float
-
-
-def normalize_ohlcv(ohlcv_array):
-    """
-    Normalize OHLCV exactly as training/inference does.
-    Input: (N, 5) array [open, high, low, close, volume]
-    Output: (5, N) normalized array
-    """
-    x = ohlcv_array.T.copy()
-    
-    # Normalize OHLC by first close (percent change)
-    first_close = x[3, 0]
-    if first_close > 0:
-        x[0:4] = (x[0:4] - first_close) / first_close * 100
-    
-    # Normalize volume by max
-    max_vol = x[4].max()
-    if max_vol > 0:
-        x[4] = x[4] / max_vol
-    else:
-        x[4] = 0
-    
-    return x  # (5, N)
-
-
-def run_simulation(
-    model_path: str = "models/ifvg_4class_cnn.pth",
-    start_date: str = None,
-    days: int = 7,
-    threshold: float = 0.35,
-    stop_atr: float = 2.0,
-    tp_atr: float = 4.0,
-    lookback: int = 30,
-    infer_every: int = 5,
-    verbose: bool = True
-) -> Dict:
-    """
-    Run simulation matching frontend logic.
-    
-    Returns summary of trades.
-    """
-    from src.data.loader import load_continuous_contract
-    from src.models.model_registry_init import IFVG4ClassWrapper
-    
-    print("=" * 60)
-    print("Backend Simulation Test")
-    print("=" * 60)
-    
-    # Load model via registry wrapper
-    print(f"\n[1] Loading model: {model_path}")
-    model = IFVG4ClassWrapper(model_path=model_path)
-    print("    Model loaded OK")
-    
-    # Load market data
-    print("\n[2] Loading market data...")
-    df = load_continuous_contract()
-    
-    if start_date:
-        import pandas as pd
-        start_dt = pd.Timestamp(start_date)
-        if start_dt.tzinfo is None:
-            start_dt = start_dt.tz_localize('America/New_York')
-        df = df[df['time'] >= start_dt]
-    
-    # Limit to N days
-    if len(df) > days * 390:  # ~390 bars per day
-        df = df.head(days * 390)
-    
-    bars = df[['open', 'high', 'low', 'close', 'volume']].values
-    times = df['time'].values
-    
-    print(f"    Loaded {len(bars)} bars")
-    
-    # Simulation state
-    active_oco: Optional[OCOBracket] = None
-    trades: List[Trade] = []
-    triggers = 0
-    
-    print(f"\n[3] Running simulation (threshold={threshold}, stop={stop_atr}ATR, tp={tp_atr}ATR)")
-    print("-" * 60)
-    
-    for idx in range(lookback, len(bars)):
-        bar = bars[idx]
-        current_open, current_high, current_low, current_close, _ = bar
-        
-        # Check OCO exit (same as frontend)
-        if active_oco is not None:
-            outcome = None
-            exit_price = 0
-            
-            if active_oco.direction == 'LONG':
-                if current_low <= active_oco.stop:
-                    outcome = 'LOSS'
-                    exit_price = active_oco.stop
-                elif current_high >= active_oco.tp:
-                    outcome = 'WIN'
-                    exit_price = active_oco.tp
-            else:  # SHORT
-                if current_high >= active_oco.stop:
-                    outcome = 'LOSS'
-                    exit_price = active_oco.stop
-                elif current_low <= active_oco.tp:
-                    outcome = 'WIN'
-                    exit_price = active_oco.tp
-            
-            if outcome:
-                is_long = active_oco.direction == 'LONG'
-                pnl = (exit_price - active_oco.entry) if is_long else (active_oco.entry - exit_price)
-                pnl_dollars = pnl * 50  # MES multiplier
-                
-                trade = Trade(
-                    entry=active_oco.entry,
-                    exit=exit_price,
-                    direction=active_oco.direction,
-                    outcome=outcome,
-                    bars_held=1,  # Simplified
-                    pnl=pnl_dollars
-                )
-                trades.append(trade)
-                
-                if verbose:
-                    print(f"  [{outcome}] {active_oco.direction} @ {active_oco.entry:.2f} -> {exit_price:.2f} = ${pnl_dollars:+.2f}")
-                
-                active_oco = None
-        
-        # Check for trigger (every N bars, no active trade)
-        if active_oco is None and idx % infer_every == 0:
-            # Build window of last 30 bars
-            window = bars[idx - lookback + 1:idx + 1]
-            
-            # Calculate ATR
-            recent = bars[max(0, idx - 13):idx + 1]
-            atr = np.mean(recent[:, 1] - recent[:, 2])  # avg(high - low)
-            if atr < 0.5:
-                atr = current_close * 0.001
-            
-            # Normalize and predict
-            ohlcv_norm = normalize_ohlcv(window)
-            result = model.predict({'ohlcv': ohlcv_norm})
-            
-            # Check trigger
-            if result['triggered'] and max(result['long_win_prob'], result['short_win_prob']) >= threshold:
-                triggers += 1
-                direction = result['direction']
-                
-                entry = current_close
-                if direction == 'LONG':
-                    stop = entry - (stop_atr * atr)
-                    tp = entry + (tp_atr * atr)
-                else:
-                    stop = entry + (stop_atr * atr)
-                    tp = entry - (tp_atr * atr)
-                
-                active_oco = OCOBracket(
-                    entry=entry,
-                    stop=stop,
-                    tp=tp,
-                    start_time=float(idx),
-                    direction=direction
-                )
-                
-                if verbose:
-                    prob = result['long_win_prob'] if direction == 'LONG' else result['short_win_prob']
-                    print(f"  [TRIGGER] {direction} @ {entry:.2f} (prob={prob:.2%}, SL={stop:.2f}, TP={tp:.2f})")
-    
-    # Summary
-    print("-" * 60)
-    wins = sum(1 for t in trades if t.outcome == 'WIN')
-    losses = len(trades) - wins
-    total_pnl = sum(t.pnl for t in trades)
-    
-    print(f"\n[4] Summary")
-    print(f"    Triggers: {triggers}")
-    print(f"    Trades:   {len(trades)}")
-    print(f"    Wins:     {wins}")
-    print(f"    Losses:   {losses}")
-    print(f"    Win Rate: {wins/max(1, len(trades)):.1%}")
-    print(f"    Total PnL: ${total_pnl:+.2f}")
-    
-    return {
-        'triggers': triggers,
-        'trades': len(trades),
-        'wins': wins,
-        'losses': losses,
-        'win_rate': wins / max(1, len(trades)),
-        'total_pnl': total_pnl,
-        'trade_details': [
-            {'entry': t.entry, 'exit': t.exit, 'direction': t.direction, 'outcome': t.outcome, 'pnl': t.pnl}
-            for t in trades
-        ]
-    }
-
-
-if __name__ == "__main__":
-    import argparse
-    from datetime import datetime
-    
-    parser = argparse.ArgumentParser(description="Backend simulation test")
-    parser.add_argument("--model", default="models/ifvg_4class_cnn.pth", help="Model path")
-    parser.add_argument("--start", default=None, help="Start date (YYYY-MM-DD)")
-    parser.add_argument("--days", type=int, default=7, help="Number of days")
-    parser.add_argument("--threshold", type=float, default=0.35, help="Trigger threshold")
-    parser.add_argument("--stop-atr", type=float, default=2.0, help="Stop loss ATR multiple")
-    parser.add_argument("--tp-atr", type=float, default=4.0, help="Take profit ATR multiple")
-    parser.add_argument("--save", action="store_true", help="Save results to experiment database")
-    parser.add_argument("--run-id", default=None, help="Run ID for saving (auto-generated if not provided)")
-    
-    args = parser.parse_args()
-    
-    results = run_simulation(
-        model_path=args.model,
-        start_date=args.start,
-        days=args.days,
-        threshold=args.threshold,
-        stop_atr=args.stop_atr,
-        tp_atr=args.tp_atr
-    )
-    
-    # Optionally save to experiment database
-    if args.save and results['trades'] > 0:
-        from src.storage import ExperimentDB
-        
-        run_id = args.run_id or f"sim_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
-        config = {
-            'model_path': args.model,
-            'start_date': args.start,
-            'days': args.days,
-            'threshold': args.threshold,
-            'stop_atr': args.stop_atr,
-            'tp_atr': args.tp_atr,
-        }
-        metrics = {
-            'total_trades': results['trades'],
-            'wins': results['wins'],
-            'losses': results['losses'],
-            'win_rate': results['win_rate'],
-            'total_pnl': results['total_pnl'],
-            'avg_pnl_per_trade': results['total_pnl'] / max(1, results['trades']),
-        }
-        
-        db = ExperimentDB()
-        db.store_run(run_id, "backend_simulation", config, metrics, args.model)
-        print(f"\n[5] Saved to experiment DB: {run_id}")
-
```
