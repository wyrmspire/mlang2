# MLang2 Software Plan â€” Path to 2.0

> **Status**: ~60â€“70% aligned with target architecture  
> **Priority**: Hardening, not invention

---

## 1ï¸âƒ£ What's Already Done Right

### âœ… Time Causality
`MarketStepper` has **no future access**. Future peeking quarantined in `labels/` only.
> This prevents 90% of future leakage bugs.

### âœ… Decision â‰  Trade â‰  Label
Distinct artifacts:
- `DecisionRecord`
- `TradeRecord`
- Counterfactual labels
- Viz exports

Essential for "when NOT to trade", comparing OCOs, training vs replay.

### âœ… Feature Split
Correct separation:
- CNN inputs (`x_price_*`)
- MLP context (`x_context`)
- HTF levels (1H / 4H)
- Time/session logic

### âœ… OCO Logic is Modular
OCO construction, processing, labeling are **isolated and parameterized**.

---

## 2ï¸âƒ£ Structural Risks to Address

### ğŸ”´ Risk #1: Training/Decision Models Not Separated
Nothing prevents trained model from being used during labeling or walk-forward.
Relying on discipline, not architecture.

### ğŸ”´ Risk #2: Policy/Model Blend
Current: `scanner â†’ trade`
Target: `scanner â†’ signals â†’ policies â†’ action â†’ execution â†’ viz`

### ğŸ”´ Risk #3: Replay is Implicit
No explicit **Replay Engine** concept. Needed for:
- Simulated real-time stepping
- Agent speed/pause/resume control
- OCO zones animating bar-by-bar

### ğŸ”´ Risk #4: Viz Schema Not Future-Proofed
Assumes one scanner, one decision source, one model.
Need slots for: multiple model votes, confidence bands, HTF overlays.

---

## 3ï¸âƒ£ Non-Negotiable Boundaries

### ğŸ§± A: Model Roles Must Be Explicit
```python
ModelRole = {
    TRAINING_ONLY,
    FROZEN_EVAL,
    REPLAY_ONLY,
    SCAN_ASSIST
}
```
**Rule**: Model with role â‰  REPLAY_ONLY cannot fire during replay.

### ğŸ§± B: Decisions Are Immutable
Once created, `DecisionRecord` never changes. Can be annotated, not rewritten.

### ğŸ§± C: Explicit Run Modes

| Mode   | Peek Future | Can Learn | Can Trade |
|--------|-------------|-----------|-----------|
| TRAIN  | âœ…          | âœ…        | âŒ        |
| REPLAY | âŒ          | âŒ        | âœ… (sim)  |
| SCAN   | âŒ          | âŒ        | âŒ        |

### ğŸ§± D: Viz is Truth
Always show: what model saw, what policies blocked, what OCO was constructed, what would have happened.

---

## 4ï¸âƒ£ 20-Phase Path to 2.0

### Phase 0.x â€” Hardening (NOW)
- [ ] 0.1 â€” Introduce `RunMode` enum (TRAIN / REPLAY / SCAN)
- [ ] 0.2 â€” Tag all models with `ModelRole`
- [ ] 0.3 â€” Enforce role checks at inference time
- [ ] 0.4 â€” Make `DecisionRecord` immutable (frozen dataclass)
- [ ] 0.5 â€” Explicit `ReplayConfig` (speed, start, end)

### Phase 1.x â€” Visualization Spine
- [ ] 1.0 â€” Unified timeline (decisions + trades + fills)
- [ ] 1.1 â€” OCO rendered as **zones**, not infinite lines
- [ ] 1.2 â€” Zoom: single trade â†” full history
- [ ] 1.3 â€” Step-forward replay (1m bars)
- [ ] 1.4 â€” HTF overlays (1H / 4H)
- [ ] 1.5 â€” Policy-block reasons visualized

### Phase 1.9 â€” Stability Gate
- [ ] 1.9 â€” Deterministic replay checksum (no new logic without passing)

### Phase 2.x â€” Policy-First Architecture
- [ ] 2.0 â€” Decision â†’ Signal â†’ Policy â†’ Action graph
- [ ] 2.1 â€” Multiple models voting (no learning yet)
- [ ] 2.2 â€” "When NOT to trade" as explicit policy
- [ ] 2.3 â€” Time-of-day / session policies
- [ ] 2.4 â€” HTF-context policy layer
- [ ] 2.5 â€” Agent allowed to toggle policies, not code

---

## Files to Modify (Phase 0.x)

| Phase | File | Change |
|-------|------|--------|
| 0.1 | `src/experiments/config.py` | Add `RunMode` enum |
| 0.1 | `src/experiments/runner.py` | Accept and enforce `RunMode` |
| 0.2 | `src/models/fusion.py` | Add `role: ModelRole` field |
| 0.3 | `src/models/fusion.py` | Check role before `forward()` |
| 0.4 | `src/datasets/decision_record.py` | `@dataclass(frozen=True)` |
| 0.5 | `src/experiments/config.py` | Add `ReplayConfig` dataclass |

---

## Not Needed Yet
- Live trading
- RL / online learning
- Production infrastructure
- External data feeds

---

## Next Steps
1. Implement Phase 0.1â€“0.5 (hardening)
2. Design Replay Engine as first-class object
3. Define policy graph interface
